{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution Plot Types Requirements\n",
    "\n",
    "## Core Distribution Types\n",
    "\n",
    "### 1. Univariate Distributions\n",
    "- **Histogram**\n",
    "  - Configurable bin width and count\n",
    "  - Option for frequency or density display\n",
    "  - Support for automatic bin optimization\n",
    "  - Ability to overlay multiple histograms\n",
    "\n",
    "- **Kernel Density Estimation (KDE)**\n",
    "  - Adjustable bandwidth parameter\n",
    "  - Multiple kernel function options (Gaussian, Epanechnikov, etc.)\n",
    "  - Ability to overlay KDE on histograms\n",
    "\n",
    "- **Box Plot**\n",
    "  - Standard five-number summary (min, Q1, median, Q3, max)\n",
    "  - Outlier detection and visualization\n",
    "  - Support for notched box plots\n",
    "  - Option for violin plot hybrid\n",
    "\n",
    "- **Violin Plot**\n",
    "  - KDE-based density visualization\n",
    "  - Symmetrical density display\n",
    "  - Option to show/hide inner box plot\n",
    "  - Configurable scale (width) options\n",
    "\n",
    "### 2. Data Distribution Requirements\n",
    "- Support for continuous numerical data\n",
    "- Handling of discrete/categorical data\n",
    "- Management of missing values\n",
    "- Automatic detection of data type\n",
    "- Support for weighted distributions\n",
    "\n",
    "### 3. Multi-Distribution Support\n",
    "- Side-by-side comparison capability\n",
    "- Overlay support with transparency\n",
    "- Grouped distribution displays\n",
    "- Faceted/grid layout options\n",
    "\n",
    "### 4. Edge Cases\n",
    "- Handle extremely skewed distributions\n",
    "- Support for multimodal distributions\n",
    "- Management of long-tail distributions\n",
    "- Zero-inflated data handling\n",
    "- Boundary condition management (e.g., non-negative data)\n",
    "\n",
    "### 5. Scale Requirements\n",
    "- Support for different data scales (linear, log, symlog)\n",
    "- Automatic scale selection based on data characteristics\n",
    "- Custom scale transformations\n",
    "- Axis limit handling\n",
    "\n",
    "### 6. Statistical Overlay Options\n",
    "- Mean indicators\n",
    "- Median lines\n",
    "- Standard deviation bands\n",
    "- Confidence intervals\n",
    "- Percentile markers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Requirements for Distribution Plots\n",
    "\n",
    "## 1. Central Tendency Metrics\n",
    "### Required Calculations\n",
    "- Arithmetic mean\n",
    "- Weighted mean\n",
    "- Geometric mean\n",
    "- Median\n",
    "- Mode (including multimodal detection)\n",
    "- Trimmed mean (configurable trim percentage)\n",
    "\n",
    "### Visual Representations\n",
    "- Vertical/horizontal reference lines\n",
    "- Annotated values with configurable precision\n",
    "- Hover/tooltip information\n",
    "- Optional confidence intervals around central tendency metrics\n",
    "\n",
    "## 2. Dispersion Measures\n",
    "### Core Statistics\n",
    "- Standard deviation\n",
    "- Variance\n",
    "- Interquartile range (IQR)\n",
    "- Mean absolute deviation\n",
    "- Coefficient of variation\n",
    "- Range (min-max)\n",
    "\n",
    "### Visualization Features\n",
    "- Standard deviation bands (Â±1,2,3 SD)\n",
    "- Percentile bands\n",
    "- Quantile ranges\n",
    "- Configurable whisker lengths for box plots\n",
    "\n",
    "## 3. Distribution Shape Metrics\n",
    "### Calculations\n",
    "- Skewness\n",
    "- Kurtosis\n",
    "- Modality testing\n",
    "- Normality tests\n",
    "  - Shapiro-Wilk test\n",
    "  - Anderson-Darling test\n",
    "  - Kolmogorov-Smirnov test\n",
    "  - Q-Q plot support\n",
    "\n",
    "### Statistical Annotations\n",
    "- Distribution type indicators\n",
    "- Shape characteristic labels\n",
    "- P-values for normality tests\n",
    "- Critical values for statistical tests\n",
    "\n",
    "## 4. Outlier Detection\n",
    "### Methods\n",
    "- IQR-based detection\n",
    "- Z-score method\n",
    "- Modified Z-score\n",
    "- Tukey's method\n",
    "- Custom threshold definitions\n",
    "\n",
    "### Visualization\n",
    "- Highlighted outlier points\n",
    "- Outlier summary statistics\n",
    "- Optional outlier labeling\n",
    "- Configurable outlier treatment\n",
    "\n",
    "## 5. Comparative Statistics\n",
    "### Between Groups\n",
    "- T-tests\n",
    "- Mann-Whitney U test\n",
    "- Kolmogorov-Smirnov two-sample test\n",
    "- Effect size calculations\n",
    "  - Cohen's d\n",
    "  - Hedges' g\n",
    "\n",
    "### Multiple Distributions\n",
    "- ANOVA support\n",
    "- Kruskal-Wallis test\n",
    "- Multiple comparison corrections\n",
    "  - Bonferroni\n",
    "  - Holm-Bonferroni\n",
    "  - False Discovery Rate (FDR)\n",
    "\n",
    "## 6. Confidence Intervals\n",
    "### Types\n",
    "- Mean CI\n",
    "- Median CI\n",
    "- Proportion CI\n",
    "- Quantile CI\n",
    "\n",
    "### Configuration\n",
    "- Configurable confidence levels\n",
    "- Bootstrap CI support\n",
    "- Asymptotic and exact methods\n",
    "- Visual representation options\n",
    "\n",
    "## 7. Density Estimation Parameters\n",
    "### KDE Configuration\n",
    "- Bandwidth selection methods\n",
    "  - Silverman's rule\n",
    "  - Scott's rule\n",
    "  - Cross-validation\n",
    "- Kernel function options\n",
    "- Boundary correction methods\n",
    "\n",
    "### Histogram Statistics\n",
    "- Optimal bin width calculations\n",
    "  - Sturges' rule\n",
    "  - Freedman-Diaconis rule\n",
    "  - Scott's rule\n",
    "- Density normalization options\n",
    "\n",
    "## 8. Export Capabilities\n",
    "### Statistical Summary\n",
    "- Comprehensive statistics table\n",
    "- Test results summary\n",
    "- Configuration parameters\n",
    "- Data quality metrics\n",
    "\n",
    "### Format Options\n",
    "- CSV export of calculations\n",
    "- PNG/SVG of visualizations with annotations\n",
    "- Statistical report generation\n",
    "- Machine-readable JSON output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm, jarque_bera\n",
    "from statsmodels.stats.diagnostic import lilliefors\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "from scipy.stats import ks_2samp, ttest_ind, mannwhitneyu\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic financial data\n",
    "np.random.seed(42)\n",
    "n_days = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate returns with slight skewness and excess kurtosis\n",
    "returns = np.random.normal(0.0005, 0.01, n_days)\n",
    "returns = returns + 0.1 * returns**3  # Add skewness\n",
    "returns = returns + np.random.standard_t(df=5, size=n_days) * 0.002  # Add fat tails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create price series\n",
    "prices = 100 * np.exp(np.cumsum(returns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DataFrame\n",
    "dates = pd.date_range(start='2022-01-01', periods=n_days, freq='B')\n",
    "df = pd.DataFrame({\n",
    "    'Date': dates,\n",
    "    'Price': prices,\n",
    "    'Returns': returns,\n",
    "    'Volume': np.random.lognormal(10, 1, n_days),\n",
    "    'Volatility': np.abs(returns) * np.sqrt(252)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_tendency(returns):\n",
    "    \"\"\"1. Central Tendency Metrics\"\"\"\n",
    "    results = {\n",
    "        'arithmetic_mean': np.mean(returns),\n",
    "        'geometric_mean': np.exp(np.mean(np.log(1 + returns))) - 1,\n",
    "        'median': np.median(returns),\n",
    "        'mode': stats.mode(returns)[0],\n",
    "        'trimmed_mean_10': stats.trim_mean(returns, 0.1)\n",
    "    }\n",
    "    \n",
    "    # Annualize returns\n",
    "    results['annualized_return'] = results['arithmetic_mean'] * 252\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = df['Returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arithmetic_mean': np.float64(0.0006392321780688051),\n",
       " 'geometric_mean': np.float64(0.0005889639302967264),\n",
       " 'median': np.float64(0.0008171283617610226),\n",
       " 'mode': np.float64(-0.03144776556281655),\n",
       " 'trimmed_mean_10': np.float64(0.0005395784029374917),\n",
       " 'annualized_return': np.float64(0.1610865088733389)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "central_tendency(returns=returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispersion_measures(returns):\n",
    "    \"\"\"2. Dispersion Measures\"\"\"\n",
    "    results = {\n",
    "        'std_dev': np.std(returns),\n",
    "        'variance': np.var(returns),\n",
    "        'ann_volatility': np.std(returns) * np.sqrt(252),\n",
    "        'IQR': np.percentile(returns, 75) - np.percentile(returns, 25),\n",
    "        'MAD': np.mean(np.abs(returns - np.mean(returns))),\n",
    "        'CV': np.std(returns) / np.mean(returns) if np.mean(returns) != 0 else np.nan,\n",
    "        'range': np.max(returns) - np.min(returns)\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'std_dev': np.float64(0.01003272972615938),\n",
       " 'variance': np.float64(0.00010065566575816206),\n",
       " 'ann_volatility': np.float64(0.15926464695925724),\n",
       " 'IQR': np.float64(0.01318178739240081),\n",
       " 'MAD': np.float64(0.007988098926295593),\n",
       " 'CV': np.float64(15.694969794026052),\n",
       " 'range': np.float64(0.07155798888588491)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dispersion_measures(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribution_shape(returns):\n",
    "    \"\"\"3. Distribution Shape Metrics\"\"\"\n",
    "    \n",
    "    # Normality tests\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(returns)\n",
    "    jb_stat, jb_p = jarque_bera(returns)\n",
    "    ks_stat, ks_p = lilliefors(returns)\n",
    "    \n",
    "    results = {\n",
    "        'skewness': stats.skew(returns),\n",
    "        'kurtosis': stats.kurtosis(returns),\n",
    "        'normality_tests': {\n",
    "            'shapiro': {'statistic': shapiro_stat, 'p_value': shapiro_p},\n",
    "            'jarque_bera': {'statistic': jb_stat, 'p_value': jb_p},\n",
    "            'lilliefors': {'statistic': ks_stat, 'p_value': ks_p}\n",
    "        }\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'skewness': np.float64(0.10146453416747092),\n",
       " 'kurtosis': np.float64(0.1495143004468691),\n",
       " 'normality_tests': {'shapiro': {'statistic': np.float64(0.9985892662344467),\n",
       "   'p_value': np.float64(0.6138332197034445)},\n",
       "  'jarque_bera': {'statistic': np.float64(2.6472805338918386),\n",
       "   'p_value': np.float64(0.2661646259877677)},\n",
       "  'lilliefors': {'statistic': np.float64(0.020163704968186646),\n",
       "   'p_value': np.float64(0.4934888055353677)}}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution_shape(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(returns):\n",
    "    \"\"\"4. Outlier Detection\"\"\"\n",
    "    \n",
    "    # IQR method\n",
    "    Q1 = np.percentile(returns, 25)\n",
    "    Q3 = np.percentile(returns, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    iqr_outliers = returns[(returns < Q1 - 1.5 * IQR) | (returns > Q3 + 1.5 * IQR)]\n",
    "    \n",
    "    # Z-score method\n",
    "    z_scores = (returns - np.mean(returns)) / np.std(returns)\n",
    "    z_outliers = returns[np.abs(z_scores) > 3]\n",
    "    \n",
    "    # Modified Z-score\n",
    "    mad = np.median(np.abs(returns - np.median(returns)))\n",
    "    modified_z = 0.6745 * (returns - np.median(returns)) / mad\n",
    "    mod_z_outliers = returns[np.abs(modified_z) > 3.5]\n",
    "    \n",
    "    results = {\n",
    "        'iqr_outliers_count': len(iqr_outliers),\n",
    "        'z_score_outliers_count': len(z_outliers),\n",
    "        'modified_z_outliers_count': len(mod_z_outliers),\n",
    "        'outlier_percentage': len(z_outliers) / len(returns) * 100\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iqr_outliers_count': 10,\n",
       " 'z_score_outliers_count': 3,\n",
       " 'modified_z_outliers_count': 1,\n",
       " 'outlier_percentage': 0.3}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect_outliers(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparative_statistics(self, other_returns):\n",
    "    \"\"\"5. Comparative Statistics\"\"\"\n",
    "    # Perform various statistical tests\n",
    "    t_stat, t_p = ttest_ind(self.returns, other_returns)\n",
    "    u_stat, u_p = mannwhitneyu(self.returns, other_returns)\n",
    "    ks_stat, ks_p = ks_2samp(self.returns, other_returns)\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt((np.var(self.returns) + np.var(other_returns)) / 2)\n",
    "    cohens_d = (np.mean(self.returns) - np.mean(other_returns)) / pooled_std\n",
    "    \n",
    "    results = {\n",
    "        't_test': {'statistic': t_stat, 'p_value': t_p},\n",
    "        'mann_whitney': {'statistic': u_stat, 'p_value': u_p},\n",
    "        'ks_test': {'statistic': ks_stat, 'p_value': ks_p},\n",
    "        'cohens_d': cohens_d\n",
    "    }\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_intervals(self, confidence=0.95):\n",
    "    \"\"\"6. Confidence Intervals\"\"\"\n",
    "    returns = self.returns\n",
    "    n = len(returns)\n",
    "    mean = np.mean(returns)\n",
    "    std_err = stats.sem(returns)\n",
    "    \n",
    "    # Mean CI\n",
    "    mean_ci = stats.t.interval(confidence, n-1, mean, std_err)\n",
    "    \n",
    "    # Median CI (bootstrap)\n",
    "    bootstrap_medians = []\n",
    "    for _ in range(1000):\n",
    "        bootstrap_sample = np.random.choice(returns, size=n, replace=True)\n",
    "        bootstrap_medians.append(np.median(bootstrap_sample))\n",
    "    median_ci = np.percentile(bootstrap_medians, [2.5, 97.5])\n",
    "    \n",
    "    results = {\n",
    "        'mean_ci': mean_ci,\n",
    "        'median_ci': median_ci,\n",
    "        'std_error': std_err\n",
    "    }\n",
    "    return results\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_estimation(self):\n",
    "    \"\"\"7. Density Estimation Parameters\"\"\"\n",
    "    returns = self.returns\n",
    "    \n",
    "    # KDE\n",
    "    kde = KDEUnivariate(returns)\n",
    "    kde.fit()\n",
    "    \n",
    "    # Histogram bins using different rules\n",
    "    n = len(returns)\n",
    "    sturges_bins = int(np.ceil(np.log2(n)) + 1)\n",
    "    fd_bins = int(np.ceil((np.max(returns) - np.min(returns)) / \n",
    "                (2 * stats.iqr(returns) / np.power(n, 1/3))))\n",
    "    scott_bins = int(np.ceil((np.max(returns) - np.min(returns)) / \n",
    "                    (3.5 * np.std(returns) / np.power(n, 1/3))))\n",
    "    \n",
    "    results = {\n",
    "        'kde_bandwidth': kde.bw,\n",
    "        'bin_counts': {\n",
    "            'sturges': sturges_bins,\n",
    "            'freedman_diaconis': fd_bins,\n",
    "            'scott': scott_bins\n",
    "        }\n",
    "    }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinancialAnalysis:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.returns = data['Returns']\n",
    "    \n",
    "    def central_tendency(self):\n",
    "        \"\"\"1. Central Tendency Metrics\"\"\"\n",
    "        results = {\n",
    "            'arithmetic_mean': np.mean(self.returns),\n",
    "            'geometric_mean': np.exp(np.mean(np.log(1 + self.returns))) - 1,\n",
    "            'median': np.median(self.returns),\n",
    "            'mode': stats.mode(self.returns)[0],\n",
    "            'trimmed_mean_10': stats.trim_mean(self.returns, 0.1)\n",
    "        }\n",
    "        \n",
    "        # Annualize returns\n",
    "        results['annualized_return'] = results['arithmetic_mean'] * 252\n",
    "        return results\n",
    "    \n",
    "    def dispersion_measures(self):\n",
    "        \"\"\"2. Dispersion Measures\"\"\"\n",
    "        returns = self.returns\n",
    "        results = {\n",
    "            'std_dev': np.std(returns),\n",
    "            'variance': np.var(returns),\n",
    "            'ann_volatility': np.std(returns) * np.sqrt(252),\n",
    "            'IQR': np.percentile(returns, 75) - np.percentile(returns, 25),\n",
    "            'MAD': np.mean(np.abs(returns - np.mean(returns))),\n",
    "            'CV': np.std(returns) / np.mean(returns) if np.mean(returns) != 0 else np.nan,\n",
    "            'range': np.max(returns) - np.min(returns)\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def distribution_shape(self):\n",
    "        \"\"\"3. Distribution Shape Metrics\"\"\"\n",
    "        returns = self.returns\n",
    "        \n",
    "        # Normality tests\n",
    "        shapiro_stat, shapiro_p = stats.shapiro(returns)\n",
    "        jb_stat, jb_p = jarque_bera(returns)\n",
    "        ks_stat, ks_p = lilliefors(returns)\n",
    "        \n",
    "        results = {\n",
    "            'skewness': stats.skew(returns),\n",
    "            'kurtosis': stats.kurtosis(returns),\n",
    "            'normality_tests': {\n",
    "                'shapiro': {'statistic': shapiro_stat, 'p_value': shapiro_p},\n",
    "                'jarque_bera': {'statistic': jb_stat, 'p_value': jb_p},\n",
    "                'lilliefors': {'statistic': ks_stat, 'p_value': ks_p}\n",
    "            }\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def detect_outliers(self):\n",
    "        \"\"\"4. Outlier Detection\"\"\"\n",
    "        returns = self.returns\n",
    "        \n",
    "        # IQR method\n",
    "        Q1 = np.percentile(returns, 25)\n",
    "        Q3 = np.percentile(returns, 75)\n",
    "        IQR = Q3 - Q1\n",
    "        iqr_outliers = returns[(returns < Q1 - 1.5 * IQR) | (returns > Q3 + 1.5 * IQR)]\n",
    "        \n",
    "        # Z-score method\n",
    "        z_scores = (returns - np.mean(returns)) / np.std(returns)\n",
    "        z_outliers = returns[np.abs(z_scores) > 3]\n",
    "        \n",
    "        # Modified Z-score\n",
    "        mad = np.median(np.abs(returns - np.median(returns)))\n",
    "        modified_z = 0.6745 * (returns - np.median(returns)) / mad\n",
    "        mod_z_outliers = returns[np.abs(modified_z) > 3.5]\n",
    "        \n",
    "        results = {\n",
    "            'iqr_outliers_count': len(iqr_outliers),\n",
    "            'z_score_outliers_count': len(z_outliers),\n",
    "            'modified_z_outliers_count': len(mod_z_outliers),\n",
    "            'outlier_percentage': len(z_outliers) / len(returns) * 100\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def comparative_statistics(self, other_returns):\n",
    "        \"\"\"5. Comparative Statistics\"\"\"\n",
    "        # Perform various statistical tests\n",
    "        t_stat, t_p = ttest_ind(self.returns, other_returns)\n",
    "        u_stat, u_p = mannwhitneyu(self.returns, other_returns)\n",
    "        ks_stat, ks_p = ks_2samp(self.returns, other_returns)\n",
    "        \n",
    "        # Effect size (Cohen's d)\n",
    "        pooled_std = np.sqrt((np.var(self.returns) + np.var(other_returns)) / 2)\n",
    "        cohens_d = (np.mean(self.returns) - np.mean(other_returns)) / pooled_std\n",
    "        \n",
    "        results = {\n",
    "            't_test': {'statistic': t_stat, 'p_value': t_p},\n",
    "            'mann_whitney': {'statistic': u_stat, 'p_value': u_p},\n",
    "            'ks_test': {'statistic': ks_stat, 'p_value': ks_p},\n",
    "            'cohens_d': cohens_d\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def confidence_intervals(self, confidence=0.95):\n",
    "        \"\"\"6. Confidence Intervals\"\"\"\n",
    "        returns = self.returns\n",
    "        n = len(returns)\n",
    "        mean = np.mean(returns)\n",
    "        std_err = stats.sem(returns)\n",
    "        \n",
    "        # Mean CI\n",
    "        mean_ci = stats.t.interval(confidence, n-1, mean, std_err)\n",
    "        \n",
    "        # Median CI (bootstrap)\n",
    "        bootstrap_medians = []\n",
    "        for _ in range(1000):\n",
    "            bootstrap_sample = np.random.choice(returns, size=n, replace=True)\n",
    "            bootstrap_medians.append(np.median(bootstrap_sample))\n",
    "        median_ci = np.percentile(bootstrap_medians, [2.5, 97.5])\n",
    "        \n",
    "        results = {\n",
    "            'mean_ci': mean_ci,\n",
    "            'median_ci': median_ci,\n",
    "            'std_error': std_err\n",
    "        }\n",
    "        return results\n",
    "    \n",
    "    def density_estimation(self):\n",
    "        \"\"\"7. Density Estimation Parameters\"\"\"\n",
    "        returns = self.returns\n",
    "        \n",
    "        # KDE\n",
    "        kde = KDEUnivariate(returns)\n",
    "        kde.fit()\n",
    "        \n",
    "        # Histogram bins using different rules\n",
    "        n = len(returns)\n",
    "        sturges_bins = int(np.ceil(np.log2(n)) + 1)\n",
    "        fd_bins = int(np.ceil((np.max(returns) - np.min(returns)) / \n",
    "                    (2 * stats.iqr(returns) / np.power(n, 1/3))))\n",
    "        scott_bins = int(np.ceil((np.max(returns) - np.min(returns)) / \n",
    "                      (3.5 * np.std(returns) / np.power(n, 1/3))))\n",
    "        \n",
    "        results = {\n",
    "            'kde_bandwidth': kde.bw,\n",
    "            'bin_counts': {\n",
    "                'sturges': sturges_bins,\n",
    "                'freedman_diaconis': fd_bins,\n",
    "                'scott': scott_bins\n",
    "            }\n",
    "        }\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analysis instance\n",
    "analysis = FinancialAnalysis(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run all analyses\n",
    "results = {\n",
    "    'central_tendency': analysis.central_tendency(),\n",
    "    'dispersion': analysis.dispersion_measures(),\n",
    "    'distribution_shape': analysis.distribution_shape(),\n",
    "    'outliers': analysis.detect_outliers(),\n",
    "    'comparative_stats': analysis.comparative_statistics(np.random.normal(0, 0.01, n_days)),\n",
    "    'confidence_intervals': analysis.confidence_intervals(),\n",
    "    'density_estimation': analysis.density_estimation()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantitative Financial Analysis Results\n",
      "========================================\n",
      "\n",
      "CENTRAL_TENDENCY\n",
      "----------------------------------------\n",
      "arithmetic_mean: 0.000639\n",
      "geometric_mean: 0.000589\n",
      "median: 0.000817\n",
      "mode: -0.031448\n",
      "trimmed_mean_10: 0.000540\n",
      "annualized_return: 0.161087\n",
      "\n",
      "DISPERSION\n",
      "----------------------------------------\n",
      "std_dev: 0.010033\n",
      "variance: 0.000101\n",
      "ann_volatility: 0.159265\n",
      "IQR: 0.013182\n",
      "MAD: 0.007988\n",
      "CV: 15.694970\n",
      "range: 0.071558\n",
      "\n",
      "DISTRIBUTION_SHAPE\n",
      "----------------------------------------\n",
      "skewness: 0.101465\n",
      "kurtosis: 0.149514\n",
      "\n",
      "normality_tests:\n",
      "  shapiro: {'statistic': np.float64(0.9985892662344467), 'p_value': np.float64(0.6138332197034445)}\n",
      "  jarque_bera: {'statistic': np.float64(2.6472805338918386), 'p_value': np.float64(0.2661646259877677)}\n",
      "  lilliefors: {'statistic': np.float64(0.020163704968186646), 'p_value': np.float64(0.4934888055353677)}\n",
      "\n",
      "OUTLIERS\n",
      "----------------------------------------\n",
      "iqr_outliers_count: 10\n",
      "z_score_outliers_count: 3\n",
      "modified_z_outliers_count: 1\n",
      "outlier_percentage: 0.300000\n",
      "\n",
      "COMPARATIVE_STATS\n",
      "----------------------------------------\n",
      "\n",
      "t_test:\n",
      "  statistic: 2.755055\n",
      "  p_value: 0.005921\n",
      "\n",
      "mann_whitney:\n",
      "  statistic: 530909.000000\n",
      "  p_value: 0.016686\n",
      "\n",
      "ks_test:\n",
      "  statistic: 0.058000\n",
      "  p_value: 0.069176\n",
      "cohens_d: 0.123271\n",
      "\n",
      "CONFIDENCE_INTERVALS\n",
      "----------------------------------------\n",
      "mean_ci: (np.float64(1.6342766178322962e-05), np.float64(0.0012621215899592873))\n",
      "median_ci: [-0.00015451  0.00155204]\n",
      "std_error: 0.000317\n",
      "\n",
      "DENSITY_ESTIMATION\n",
      "----------------------------------------\n",
      "kde_bandwidth: 0.002600\n",
      "\n",
      "bin_counts:\n",
      "  sturges: 11\n",
      "  freedman_diaconis: 28\n",
      "  scott: 21\n"
     ]
    }
   ],
   "source": [
    "# Print formatted results\n",
    "def print_results(results):\n",
    "    print(\"\\nQuantitative Financial Analysis Results\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    for category, metrics in results.items():\n",
    "        print(f\"\\n{category.upper()}\")\n",
    "        print(\"-\"*40)\n",
    "        \n",
    "        if isinstance(metrics, dict):\n",
    "            for metric, value in metrics.items():\n",
    "                if isinstance(value, dict):\n",
    "                    print(f\"\\n{metric}:\")\n",
    "                    for sub_metric, sub_value in value.items():\n",
    "                        print(f\"  {sub_metric}: {sub_value:.6f}\" if isinstance(sub_value, float) \n",
    "                              else f\"  {sub_metric}: {sub_value}\")\n",
    "                else:\n",
    "                    print(f\"{metric}: {value:.6f}\" if isinstance(value, float) \n",
    "                          else f\"{metric}: {value}\")\n",
    "\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
